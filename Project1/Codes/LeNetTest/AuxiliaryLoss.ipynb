{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor, nn\n",
    "from loading_datas import  generate_pair_sets\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pairs, train_target, train_classes, test_pairs, test_target, test_classes = generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net1,self).__init__()\n",
    "\n",
    "    self.conv11 = nn.Conv2d(1,16,3)\n",
    "    self.conv12 = nn.Conv2d(16,32,3)\n",
    "\n",
    "    self.conv21 = nn.Conv2d(1,16,3)\n",
    "    self.conv22 = nn.Conv2d(16,32,3)\n",
    "\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv11(c1))\n",
    "    c1 = self.pool(c1)\n",
    "    c1 = F.relu(self.conv12(c1))\n",
    "    \n",
    "\n",
    "    # Channel 2\n",
    "    c2 = F.relu(self.conv21(c2))\n",
    "    c2 = self.pool(c2)\n",
    "    c2 = F.relu(self.conv22(c2))\n",
    "    \n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "class Net1_aux(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv11 = nn.Conv2d(1,16,3)\n",
    "    self.conv12 = nn.Conv2d(16,32,3)\n",
    "\n",
    "    self.conv21 = nn.Conv2d(1,16,3)\n",
    "    self.conv22 = nn.Conv2d(16,32,3)\n",
    "\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "  def aux(self, img1, img2):\n",
    "    img = output = torch.cat((img1, img2), 1)\n",
    "    nb_el = img.size()[1] * img.size()[2] * img.size()[3]\n",
    "    # print(nb_el)\n",
    "    output = img.view(-1, nb_el)\n",
    "    # print(output.size())\n",
    "    fc1_aux = nn.Linear(nb_el, 64)\n",
    "    output = F.relu(fc1_aux(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv11(c1))\n",
    "    c2 = F.relu(self.conv21(c2))\n",
    "    output_aux1 = self.aux(c1, c2)\n",
    "\n",
    "    c1 = self.pool(c1)\n",
    "    c2 = self.pool(c2)\n",
    "    output_aux2 = self.aux(c1, c2)\n",
    "\n",
    "    \n",
    "\n",
    "    c1 = F.relu(self.conv12(c1))\n",
    "    c2 = F.relu(self.conv22(c2))\n",
    "    \n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output, output_aux1, output_aux2\n",
    "\n",
    "class Net2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net2,self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(1,16,3)\n",
    "    self.conv2 = nn.Conv2d(16,32,3)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv1(c1))\n",
    "    c1 = self.pool(c1)\n",
    "    c1 = F.relu(self.conv2(c1))\n",
    "\n",
    "    # Channel 2\n",
    "    c2 = F.relu(self.conv1(c2))\n",
    "    c2 = self.pool(c2)\n",
    "    c2 = F.relu(self.conv2(c2))\n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "class Net2_aux(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(1,16,3)\n",
    "    self.conv2 = nn.Conv2d(16,32,3)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "\n",
    "  def aux(self, img1, img2):\n",
    "    img = output = torch.cat((img1, img2), 1)\n",
    "    nb_el = img.size()[1] * img.size()[2] * img.size()[3]\n",
    "    # print(nb_el)\n",
    "    output = img.view(-1, nb_el)\n",
    "    # print(output.size())\n",
    "    fc1_aux = nn.Linear(nb_el, 64)\n",
    "    output = F.relu(fc1_aux(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "    return output\n",
    "    \n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv1(c1))\n",
    "    c2 = F.relu(self.conv1(c2))\n",
    "\n",
    "    output_aux1 = self.aux(c1, c2)\n",
    "\n",
    "    c1 = self.pool(c1)\n",
    "    c2 = self.pool(c2)\n",
    "    output_aux2 = self.aux(c1, c2)\n",
    "\n",
    "    c1 = F.relu(self.conv2(c1))\n",
    "    c2 = F.relu(self.conv2(c2))\n",
    "\n",
    "    # Channel 2\n",
    "    \n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output, output_aux1, output_aux2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target,batch_size, aux):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for inputs, targets in zip(data_input.split(batch_size), data_target.split(batch_size)):\n",
    "        if aux:\n",
    "            output = model(inputs)[0]\n",
    "        else:\n",
    "            output = model(inputs)\n",
    "        for k in range(len(targets)):\n",
    "            \n",
    "            if torch.argmax(output[k]) != torch.argmax(targets[k]):\n",
    "                nb_data_errors = nb_data_errors + 1\n",
    "                \n",
    "\n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, nb_epochs, batch_size = 1e-2, 50, 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1 / Train accuracy (%): 51.40 / Test accuracy (%): 49.90\n",
      "Epoch # 2 / Train accuracy (%): 48.10 / Test accuracy (%): 49.60\n",
      "Epoch # 3 / Train accuracy (%): 51.80 / Test accuracy (%): 50.40\n",
      "Epoch # 4 / Train accuracy (%): 49.40 / Test accuracy (%): 48.00\n",
      "Epoch # 5 / Train accuracy (%): 49.90 / Test accuracy (%): 48.00\n",
      "Epoch # 6 / Train accuracy (%): 51.00 / Test accuracy (%): 48.10\n",
      "Epoch # 7 / Train accuracy (%): 53.20 / Test accuracy (%): 50.00\n",
      "Epoch # 8 / Train accuracy (%): 54.50 / Test accuracy (%): 50.70\n",
      "Epoch # 9 / Train accuracy (%): 56.10 / Test accuracy (%): 51.80\n",
      "Epoch # 10 / Train accuracy (%): 56.60 / Test accuracy (%): 52.30\n",
      "Epoch # 11 / Train accuracy (%): 57.90 / Test accuracy (%): 54.50\n",
      "Epoch # 12 / Train accuracy (%): 59.30 / Test accuracy (%): 56.10\n",
      "Epoch # 13 / Train accuracy (%): 60.90 / Test accuracy (%): 57.20\n",
      "Epoch # 14 / Train accuracy (%): 63.00 / Test accuracy (%): 58.60\n",
      "Epoch # 15 / Train accuracy (%): 64.40 / Test accuracy (%): 59.20\n",
      "Epoch # 16 / Train accuracy (%): 65.50 / Test accuracy (%): 60.80\n",
      "Epoch # 17 / Train accuracy (%): 67.10 / Test accuracy (%): 62.10\n",
      "Epoch # 18 / Train accuracy (%): 68.90 / Test accuracy (%): 63.40\n",
      "Epoch # 19 / Train accuracy (%): 70.20 / Test accuracy (%): 64.30\n",
      "Epoch # 20 / Train accuracy (%): 72.30 / Test accuracy (%): 64.90\n",
      "Epoch # 21 / Train accuracy (%): 73.10 / Test accuracy (%): 66.20\n",
      "Epoch # 22 / Train accuracy (%): 74.20 / Test accuracy (%): 66.60\n",
      "Epoch # 23 / Train accuracy (%): 74.30 / Test accuracy (%): 67.20\n",
      "Epoch # 24 / Train accuracy (%): 75.20 / Test accuracy (%): 67.20\n",
      "Epoch # 25 / Train accuracy (%): 76.30 / Test accuracy (%): 68.20\n",
      "Epoch # 26 / Train accuracy (%): 77.00 / Test accuracy (%): 68.90\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-497642bf12e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# print(nb_error)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtrain_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcompute_nb_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtrain_pairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mtest_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcompute_nb_errors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_pairs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_target\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest_pairs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Epoch # {e+1} / Train accuracy (%): {train_errors:.2f} / Test accuracy (%): {test_errors:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-0168ae363a89>\u001b[0m in \u001b[0;36mcompute_nb_errors\u001b[1;34m(model, data_input, data_target, batch_size, aux)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[0mnb_data_errors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_data_errors\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = Net1()\n",
    "# model = Net2()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for e in range(nb_epochs):\n",
    "    for input, targets in zip(train_pairs.split(batch_size), train_target.split(batch_size)):\n",
    "        # output, output_aux1, output_aux2 = model(input)\n",
    "        output = model(input)\n",
    "        loss = criterion(output, targets)\n",
    "        # loss_aux1 = criterion(output_aux1, targets)\n",
    "        # loss_aux2 = criterion(output_aux2, targets)\n",
    "\n",
    "        # print(loss)\n",
    "        # print(loss)\n",
    "        # loss_total = loss + loss_aux1 + loss_aux2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "    # nb_error = compute_nb_errors(model, train_pairs, train_target, batch_size, aux=False)\n",
    "    # print(nb_error)\n",
    "\n",
    "    train_errors = 100 * (1 - compute_nb_errors(model, train_pairs, train_target,batch_size, False)/train_pairs.size(0))\n",
    "    test_errors = 100 * (1 - compute_nb_errors(model, test_pairs, test_target,batch_size, False)/test_pairs.size(0))\n",
    "    print(f\"Epoch # {e+1} / Train accuracy (%): {train_errors:.2f} / Test accuracy (%): {test_errors:.2f}\")\n",
    "\n",
    "        \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net1_aux()\n",
    "# model = Net2()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for e in range(nb_epochs):\n",
    "    for input, targets in zip(train_pairs.split(batch_size), train_target.split(batch_size)):\n",
    "        output, output_aux1, output_aux2 = model(input)\n",
    "        # output = model(input)\n",
    "        loss = criterion(output, targets)\n",
    "        loss_aux1 = criterion(output_aux1, targets)\n",
    "        loss_aux2 = criterion(output_aux2, targets)\n",
    "\n",
    "        # print(loss)\n",
    "        # print(loss)\n",
    "        loss_total = loss + loss_aux1 + loss_aux2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "    nb_error = compute_nb_errors(model, train_pairs, train_target, batch_size, aux=True)\n",
    "    # print(nb_error)\n",
    "\n",
    "    train_errors = 100 * (1 - compute_nb_errors(model, train_pairs, train_target,batch_size, True)/train_pairs.size(0))\n",
    "    test_errors = 100 * (1 - compute_nb_errors(model, test_pairs, test_target,batch_size, True)/test_pairs.size(0))\n",
    "    print(f\"Epoch # {e+1} / Train accuracy (%): {train_errors:.2f} / Test accuracy (%): {test_errors:.2f}\")\n",
    "\n",
    "        \n",
    "    optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ba3a57230124009c6424c7ef190e9e1af0f7e50ef2b850056b2994b0610e57d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
