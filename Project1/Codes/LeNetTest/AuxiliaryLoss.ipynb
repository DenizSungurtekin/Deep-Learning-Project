{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor, nn\n",
    "from loading_datas import  generate_pair_sets\n",
    "import torch.nn.functional as F\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000]) torch.Size([1000])\n",
      "tensor([1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
      "        1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
      "        0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
      "        1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
      "        0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
      "        1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
      "        0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
      "        1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1,\n",
      "        1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
      "        0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0,\n",
      "        1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1,\n",
      "        0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
      "        1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
      "        0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "train_pairs, train_target, train_classes, test_pairs, test_target, test_classes = generate_pair_sets(1000)\n",
    "print(train_target.size(), test_target.size())\n",
    "print(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net1,self).__init__()\n",
    "\n",
    "    self.conv11 = nn.Conv2d(1,16,3)\n",
    "    self.conv12 = nn.Conv2d(16,32,3)\n",
    "    self.conv1 = nn.Conv2d()\n",
    "\n",
    "    self.conv21 = nn.Conv2d(1,16,3)\n",
    "    self.conv22 = nn.Conv2d(16,32,3)\n",
    "\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv11(c1))\n",
    "    c1 = self.pool(c1)\n",
    "    c1 = F.relu(self.conv12(c1))\n",
    "    \n",
    "\n",
    "    # Channel 2\n",
    "    c2 = F.relu(self.conv21(c2))\n",
    "    c2 = self.pool(c2)\n",
    "    c2 = F.relu(self.conv22(c2))\n",
    "    \n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "class Net1_aux(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.conv11 = nn.Conv2d(1,16,3)\n",
    "    self.conv12 = nn.Conv2d(16,32,3)\n",
    "\n",
    "    self.conv21 = nn.Conv2d(1,16,3)\n",
    "    self.conv22 = nn.Conv2d(16,32,3)\n",
    "\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "  def aux(self, img1, img2):\n",
    "    img = output = torch.cat((img1, img2), 1)\n",
    "    nb_el = img.size()[1] * img.size()[2] * img.size()[3]\n",
    "    # print(nb_el)\n",
    "    output = img.view(-1, nb_el)\n",
    "    # print(output.size())\n",
    "    fc1_aux = nn.Linear(nb_el, 64)\n",
    "    output = F.relu(fc1_aux(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "    return output\n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv11(c1))\n",
    "    c2 = F.relu(self.conv21(c2))\n",
    "    output_aux1 = self.aux(c1, c2)\n",
    "\n",
    "    c1 = self.pool(c1)\n",
    "    c2 = self.pool(c2)\n",
    "    output_aux2 = self.aux(c1, c2)\n",
    "\n",
    "    \n",
    "\n",
    "    c1 = F.relu(self.conv12(c1))\n",
    "    c2 = F.relu(self.conv22(c2))\n",
    "    \n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output, output_aux1, output_aux2\n",
    "\n",
    "class Net2(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Net2,self).__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(1,16,3)\n",
    "    self.conv2 = nn.Conv2d(16,32,3)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv1(c1))\n",
    "    c1 = self.pool(c1)\n",
    "    c1 = F.relu(self.conv2(c1))\n",
    "\n",
    "    # Channel 2\n",
    "    c2 = F.relu(self.conv1(c2))\n",
    "    c2 = self.pool(c2)\n",
    "    c2 = F.relu(self.conv2(c2))\n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "class Net2_aux(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    \n",
    "    self.conv1 = nn.Conv2d(1,16,3)\n",
    "    self.conv2 = nn.Conv2d(16,32,3)\n",
    "    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)\n",
    "\n",
    "    self.fc1 = nn.Linear(64*4*4,64)\n",
    "    self.fc2 = nn.Linear(64,32)\n",
    "    self.fc3 = nn.Linear(32,2)\n",
    "\n",
    "\n",
    "  def aux(self, img1, img2):\n",
    "    img = output = torch.cat((img1, img2), 1)\n",
    "    nb_el = img.size()[1] * img.size()[2] * img.size()[3]\n",
    "    # print(nb_el)\n",
    "    output = img.view(-1, nb_el)\n",
    "    # print(output.size())\n",
    "    fc1_aux = nn.Linear(nb_el, 64)\n",
    "    output = F.relu(fc1_aux(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "    return output\n",
    "    \n",
    "\n",
    "  def forward(self,x): \n",
    "    # spliting the channels\n",
    "    c1 = torch.narrow(x,1,0,1)\n",
    "    c2 = torch.narrow(x,1,1,1)\n",
    "\n",
    "    # Channel 1\n",
    "    c1 = F.relu(self.conv1(c1))\n",
    "    c2 = F.relu(self.conv1(c2))\n",
    "\n",
    "    output_aux1 = self.aux(c1, c2)\n",
    "\n",
    "    c1 = self.pool(c1)\n",
    "    c2 = self.pool(c2)\n",
    "    output_aux2 = self.aux(c1, c2)\n",
    "\n",
    "    c1 = F.relu(self.conv2(c1))\n",
    "    c2 = F.relu(self.conv2(c2))\n",
    "\n",
    "    # Channel 2\n",
    "    \n",
    "\n",
    "\n",
    "    output = torch.cat((c1,c2),1)\n",
    "    output = output.view(-1,64*4*4)\n",
    "   \n",
    "    output = F.relu(self.fc1(output))\n",
    "    output = F.relu(self.fc2(output))\n",
    "    output = self.fc3(output)\n",
    "\n",
    "    return output, output_aux1, output_aux2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_errors(model, data_input, data_target,batch_size):\n",
    "\n",
    "    nb_data_errors = 0\n",
    "\n",
    "    for inputs, targets in zip(data_input.split(batch_size), data_target.split(batch_size)):\n",
    "        # output = model(inputs)[0]\n",
    "        output = model(inputs)\n",
    "        # print(output)\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        # print(predicted_classes)\n",
    "        for k in range(len(targets)):\n",
    "            if targets[k] != predicted_classes[k]:\n",
    "                nb_data_errors = nb_data_errors + 1        \n",
    "    return nb_data_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, nb_epochs, batch_size = 0.01, 30, 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1 / Train accuracy (%): 69.30 / Test accuracy (%): 68.10\n",
      "Epoch # 2 / Train accuracy (%): 80.40 / Test accuracy (%): 74.60\n",
      "Epoch # 3 / Train accuracy (%): 83.90 / Test accuracy (%): 78.20\n",
      "Epoch # 4 / Train accuracy (%): 85.60 / Test accuracy (%): 78.80\n",
      "Epoch # 5 / Train accuracy (%): 88.70 / Test accuracy (%): 79.80\n",
      "Epoch # 6 / Train accuracy (%): 90.30 / Test accuracy (%): 80.90\n",
      "Epoch # 7 / Train accuracy (%): 90.90 / Test accuracy (%): 80.90\n",
      "Epoch # 8 / Train accuracy (%): 92.30 / Test accuracy (%): 82.60\n",
      "Epoch # 9 / Train accuracy (%): 93.50 / Test accuracy (%): 83.00\n",
      "Epoch # 10 / Train accuracy (%): 85.60 / Test accuracy (%): 79.40\n",
      "Epoch # 11 / Train accuracy (%): 94.60 / Test accuracy (%): 82.60\n",
      "Epoch # 12 / Train accuracy (%): 95.70 / Test accuracy (%): 82.60\n",
      "Epoch # 13 / Train accuracy (%): 96.00 / Test accuracy (%): 83.10\n",
      "Epoch # 14 / Train accuracy (%): 94.30 / Test accuracy (%): 81.60\n",
      "Epoch # 15 / Train accuracy (%): 98.20 / Test accuracy (%): 84.00\n",
      "Epoch # 16 / Train accuracy (%): 98.00 / Test accuracy (%): 83.00\n",
      "Epoch # 17 / Train accuracy (%): 98.70 / Test accuracy (%): 84.50\n",
      "Epoch # 18 / Train accuracy (%): 99.50 / Test accuracy (%): 84.60\n",
      "Epoch # 19 / Train accuracy (%): 99.50 / Test accuracy (%): 84.10\n",
      "Epoch # 20 / Train accuracy (%): 99.70 / Test accuracy (%): 84.30\n",
      "Epoch # 21 / Train accuracy (%): 99.90 / Test accuracy (%): 84.30\n",
      "Epoch # 22 / Train accuracy (%): 99.90 / Test accuracy (%): 84.00\n",
      "Epoch # 23 / Train accuracy (%): 99.90 / Test accuracy (%): 84.10\n",
      "Epoch # 24 / Train accuracy (%): 99.90 / Test accuracy (%): 83.70\n",
      "Epoch # 25 / Train accuracy (%): 99.90 / Test accuracy (%): 83.70\n",
      "Epoch # 26 / Train accuracy (%): 100.00 / Test accuracy (%): 83.80\n",
      "Epoch # 27 / Train accuracy (%): 100.00 / Test accuracy (%): 83.80\n",
      "Epoch # 28 / Train accuracy (%): 100.00 / Test accuracy (%): 83.80\n",
      "Epoch # 29 / Train accuracy (%): 100.00 / Test accuracy (%): 83.80\n",
      "Epoch # 30 / Train accuracy (%): 100.00 / Test accuracy (%): 83.70\n"
     ]
    }
   ],
   "source": [
    "model = Net2()\n",
    "# model = Net2()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for e in range(nb_epochs):\n",
    "    for input, targets in zip(train_pairs.split(batch_size), train_target.split(batch_size)):\n",
    "        # output, output_aux1, output_aux2 = model(input)\n",
    "        output = model(input)\n",
    "        loss = criterion(output, targets)\n",
    "        # loss_aux1 = criterion(output_aux1, targets)\n",
    "        # loss_aux2 = criterion(output_aux2, targets)\n",
    "\n",
    "        # print(loss)\n",
    "        # print(loss)\n",
    "        # loss_total = loss + loss_aux1 + loss_aux2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # nb_error = compute_nb_errors(model, train_pairs, train_target, batch_size, aux=False)\n",
    "    # print(nb_error)\n",
    "\n",
    "    train_errors = 100 * (1 - compute_nb_errors(model, train_pairs, train_target,batch_size)/train_pairs.size(0))\n",
    "    test_errors = 100 * (1 - compute_nb_errors(model, test_pairs, test_target,batch_size)/test_pairs.size(0))\n",
    "    print(f\"Epoch # {e+1} / Train accuracy (%): {train_errors:.2f} / Test accuracy (%): {test_errors:.2f}\")\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch # 1 / Train accuracy (%): 77.60 / Test accuracy (%): 72.40\n",
      "Epoch # 2 / Train accuracy (%): 73.40 / Test accuracy (%): 68.30\n",
      "Epoch # 3 / Train accuracy (%): 84.30 / Test accuracy (%): 76.90\n",
      "Epoch # 4 / Train accuracy (%): 84.40 / Test accuracy (%): 77.70\n",
      "Epoch # 5 / Train accuracy (%): 88.60 / Test accuracy (%): 79.10\n",
      "Epoch # 6 / Train accuracy (%): 82.50 / Test accuracy (%): 77.10\n",
      "Epoch # 7 / Train accuracy (%): 91.40 / Test accuracy (%): 80.00\n",
      "Epoch # 8 / Train accuracy (%): 93.40 / Test accuracy (%): 80.80\n",
      "Epoch # 9 / Train accuracy (%): 91.10 / Test accuracy (%): 79.30\n",
      "Epoch # 10 / Train accuracy (%): 95.30 / Test accuracy (%): 81.70\n",
      "Epoch # 11 / Train accuracy (%): 96.60 / Test accuracy (%): 82.00\n",
      "Epoch # 12 / Train accuracy (%): 91.40 / Test accuracy (%): 80.30\n",
      "Epoch # 13 / Train accuracy (%): 90.30 / Test accuracy (%): 78.10\n",
      "Epoch # 14 / Train accuracy (%): 93.80 / Test accuracy (%): 80.80\n",
      "Epoch # 15 / Train accuracy (%): 96.10 / Test accuracy (%): 82.20\n",
      "Epoch # 16 / Train accuracy (%): 98.00 / Test accuracy (%): 82.90\n",
      "Epoch # 17 / Train accuracy (%): 98.20 / Test accuracy (%): 82.30\n",
      "Epoch # 18 / Train accuracy (%): 98.40 / Test accuracy (%): 83.00\n",
      "Epoch # 19 / Train accuracy (%): 99.40 / Test accuracy (%): 83.60\n",
      "Epoch # 20 / Train accuracy (%): 100.00 / Test accuracy (%): 84.00\n",
      "Epoch # 21 / Train accuracy (%): 100.00 / Test accuracy (%): 84.20\n",
      "Epoch # 22 / Train accuracy (%): 100.00 / Test accuracy (%): 84.10\n",
      "Epoch # 23 / Train accuracy (%): 100.00 / Test accuracy (%): 83.90\n",
      "Epoch # 24 / Train accuracy (%): 100.00 / Test accuracy (%): 83.90\n",
      "Epoch # 25 / Train accuracy (%): 100.00 / Test accuracy (%): 83.70\n",
      "Epoch # 26 / Train accuracy (%): 100.00 / Test accuracy (%): 83.60\n",
      "Epoch # 27 / Train accuracy (%): 100.00 / Test accuracy (%): 83.90\n",
      "Epoch # 28 / Train accuracy (%): 100.00 / Test accuracy (%): 83.50\n",
      "Epoch # 29 / Train accuracy (%): 100.00 / Test accuracy (%): 83.60\n",
      "Epoch # 30 / Train accuracy (%): 100.00 / Test accuracy (%): 83.80\n"
     ]
    }
   ],
   "source": [
    "model = Net1()\n",
    "# model = Net2()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = lr)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "for e in range(nb_epochs):\n",
    "    for input, targets in zip(train_pairs.split(batch_size), train_target.split(batch_size)):\n",
    "        # output, output_aux1, output_aux2 = model(input)\n",
    "        output = model(input)\n",
    "        loss = criterion(output, targets)\n",
    "        # loss_aux1 = criterion(output_aux1, targets)\n",
    "        # loss_aux2 = criterion(output_aux2, targets)\n",
    "\n",
    "        # print(loss)\n",
    "        # print(loss)\n",
    "        # loss_total = loss + loss_aux1 + loss_aux2\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # nb_error = compute_nb_errors(model, train_pairs, train_target, batch_size, aux=True)\n",
    "    # print(nb_error)\n",
    "\n",
    "    train_errors = 100 * (1 - compute_nb_errors(model, train_pairs, train_target,batch_size)/train_pairs.size(0))\n",
    "    test_errors = 100 * (1 - compute_nb_errors(model, test_pairs, test_target,batch_size)/test_pairs.size(0))\n",
    "    print(f\"Epoch # {e+1} / Train accuracy (%): {train_errors:.2f} / Test accuracy (%): {test_errors:.2f}\")\n",
    "\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ba3a57230124009c6424c7ef190e9e1af0f7e50ef2b850056b2994b0610e57d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
