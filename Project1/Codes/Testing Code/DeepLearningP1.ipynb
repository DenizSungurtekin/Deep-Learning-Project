{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningP1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZIg6qLQCkQ5"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch import optim\n",
        "import dlc_pratical_prologue as prologue\n",
        "from loading_datas import  generate_pair_sets\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S7Ddk31C5PE"
      },
      "source": [
        "## Data set\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSbCT8p9C_jP"
      },
      "source": [
        "N = 1000\n",
        "train_input, train_target, train_classes, test_input, test_target, test_classes = generate_pair_sets(N)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "piCYIcm5JmCa",
        "outputId": "adb2b43d-c805-43b8-ccbe-8dc67e4c3d9a"
      },
      "source": [
        "# Double checking\n",
        "print(\"Training Set\")\n",
        "print(train_input.size())\n",
        "print(train_target.size())\n",
        "print(train_classes.size())\n",
        "print(\"-------------------\")\n",
        "print(\"Testing Set\")\n",
        "print(test_input.size())\n",
        "print(test_target.size())\n",
        "print(test_classes.size())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Set\n",
            "torch.Size([1000, 2, 14, 14])\n",
            "torch.Size([1000])\n",
            "torch.Size([1000, 2])\n",
            "-------------------\n",
            "Testing Set\n",
            "torch.Size([1000, 2, 14, 14])\n",
            "torch.Size([1000])\n",
            "torch.Size([1000, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iei7sYugDAC1"
      },
      "source": [
        "## Helping functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aJqi4xbDnaH"
      },
      "source": [
        "\"\"\"\n",
        "Input :-\n",
        "\n",
        "model : Pytorch NN model\n",
        "input_data : Tensor of N X 2 X 14 X 14\n",
        "target_data : Tensor of N X 1\n",
        "batch_size : Size of the batch\n",
        "\n",
        "-----------------------------------\n",
        "\n",
        "Output :-\n",
        "\n",
        "The number of samples not well classified\n",
        "\"\"\"\n",
        "def compute_nb_errors(model, data_input, data_target,batch_size):\n",
        "\n",
        "    nb_data_errors = 0\n",
        "\n",
        "    for inputs, targets in zip(data_input.split(batch_size), data_target.split(batch_size)):\n",
        "        output = model(inputs)\n",
        "        _, predicted_classes = torch.max(output, 1)\n",
        "        for k in range(len(targets)):\n",
        "            if targets[k] != predicted_classes[k]:\n",
        "                nb_data_errors = nb_data_errors + 1\n",
        "                \n",
        "    return nb_data_errors\n",
        "\n",
        "\"\"\"\n",
        "Input :-\n",
        "\n",
        "model : Pytorch NN model\n",
        "train_input : Tensor of N x 2 x 14 x 14\n",
        "train_target : Tensor of N x 1\n",
        "train_classes : Tensor of N x 2\n",
        "\n",
        "test_input : Tensor of N x 2 x 14 x 14\n",
        "test_target : Tensor of N x 1\n",
        "test_classes : Tensor of N x 2\n",
        "\n",
        "epochs : the number of passes of the entire training dataset\n",
        "eta : learning parameter\n",
        "\n",
        "batch_size : Size of the batch\n",
        "\n",
        "-----------------------------------\n",
        "\n",
        "Output :-\n",
        "\n",
        "The number of samples not well classified\n",
        "\n",
        "\"\"\"\n",
        "eta = 0.01\n",
        "def training_model(model,\n",
        "                   train_input,train_target,train_classes,\n",
        "                   test_input,test_target,test_classes,\n",
        "                   eta,epochs = 25,\n",
        "                   batch_size = 50):\n",
        "  \n",
        "  train_acc = []\n",
        "  test_acc = []\n",
        "\n",
        "  # define criterion and optimizer\n",
        "  # need to check the other possibilities\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = optim.SGD(model.parameters(), lr = eta)\n",
        "\n",
        "  for e in range(0,epochs):\n",
        "\n",
        "    for inputs,target in zip(train_input.split(batch_size),train_target.split(batch_size)):\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, target)\n",
        "\n",
        "      # optimising parameters\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step() \n",
        "\n",
        "  \n",
        "\n",
        "    train_errors = 0\n",
        "    train_errors = 100 * (1 - compute_nb_errors(model, train_input, train_target,batch_size)/train_input.size(0))\n",
        "    test_errors = 0\n",
        "    test_errors = 100 * (1 - compute_nb_errors(model, test_input, test_target,batch_size)/test_input.size(0))\n",
        "    print(f\"Epoch # {e+1} / Train accuracy (%): {train_errors:.2f} / Test accuracy (%): {test_errors:.2f}\")\n",
        "     \n",
        "\n",
        "\n",
        "  return \" \"\n",
        "  \n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phvYZyCYbqNk"
      },
      "source": [
        ""
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtWUlBicKfIO"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZsCfajbS8_D"
      },
      "source": [
        "# parameters\n",
        "eta = 0.01"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmzOlcpqLwb_"
      },
      "source": [
        "\n",
        "# Net without Weight sharing\n",
        "class Net1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net1,self).__init__()\n",
        "\n",
        "    self.conv11 = nn.Conv2d(1,16,3)\n",
        "    self.conv12 = nn.Conv2d(16,32,3)\n",
        "\n",
        "    self.conv21 = nn.Conv2d(1,16,3)\n",
        "    self.conv22 = nn.Conv2d(16,32,3)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(64*4*4,64)\n",
        "    self.fc2 = nn.Linear(64,32)\n",
        "    self.fc3 = nn.Linear(32,2)\n",
        "\n",
        "  def forward(self,x): \n",
        "    # spliting the channels\n",
        "    c1 = torch.narrow(x,1,0,1)\n",
        "    c2 = torch.narrow(x,1,1,1)\n",
        "\n",
        "    # Channel 1\n",
        "    c1 = F.relu(self.conv11(c1))\n",
        "    c1 = self.pool(c1)\n",
        "    c1 = F.relu(self.conv12(c1))\n",
        "    \n",
        "\n",
        "    # Channel 2\n",
        "    c2 = F.relu(self.conv21(c2))\n",
        "    c2 = self.pool(c2)\n",
        "    c2 = F.relu(self.conv22(c2))\n",
        "    \n",
        "\n",
        "\n",
        "    output = torch.cat((c1,c2),1)\n",
        "    output = output.view(-1,64*4*4)\n",
        "   \n",
        "    output = F.relu(self.fc1(output))\n",
        "    output = F.relu(self.fc2(output))\n",
        "    output = self.fc3(output)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Net without Weight sharing\n",
        "class Net2(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net2,self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(1,16,3)\n",
        "    self.conv2 = nn.Conv2d(16,32,3)\n",
        "    self.pool = nn.MaxPool2d(kernel_size=(2,2),stride=2)\n",
        "\n",
        "    self.fc1 = nn.Linear(64*4*4,64)\n",
        "    self.fc2 = nn.Linear(64,32)\n",
        "    self.fc3 = nn.Linear(32,2)\n",
        "\n",
        "  def forward(self,x): \n",
        "    # spliting the channels\n",
        "    c1 = torch.narrow(x,1,0,1)\n",
        "    c2 = torch.narrow(x,1,1,1)\n",
        "\n",
        "    # Channel 1\n",
        "    c1 = F.relu(self.conv1(c1))\n",
        "    c1 = self.pool(c1)\n",
        "    c1 = F.relu(self.conv2(c1))\n",
        "\n",
        "    # Channel 2\n",
        "    c2 = F.relu(self.conv1(c2))\n",
        "    c2 = self.pool(c2)\n",
        "    c2 = F.relu(self.conv2(c2))\n",
        "\n",
        "\n",
        "    output = torch.cat((c1,c2),1)\n",
        "    output = output.view(-1,64*4*4)\n",
        "   \n",
        "    output = F.relu(self.fc1(output))\n",
        "    output = F.relu(self.fc2(output))\n",
        "    output = self.fc3(output)\n",
        "\n",
        "    return output\n",
        "\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "rmTOtfsJIoWn",
        "outputId": "a05734aa-bcf4-4a31-9792-216523b9b06d"
      },
      "source": [
        "# Net without weight sharing\n",
        "model1 = Net1()\n",
        "training_model(model1,train_input,train_target,train_classes,test_input,test_target,test_classes,eta,epochs = 25,batch_size = 50)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch # 1 / Train accuracy (%): 64.20 / Test accuracy (%): 59.90\n",
            "Epoch # 2 / Train accuracy (%): 78.10 / Test accuracy (%): 76.60\n",
            "Epoch # 3 / Train accuracy (%): 79.30 / Test accuracy (%): 79.20\n",
            "Epoch # 4 / Train accuracy (%): 83.30 / Test accuracy (%): 80.20\n",
            "Epoch # 5 / Train accuracy (%): 82.40 / Test accuracy (%): 81.00\n",
            "Epoch # 6 / Train accuracy (%): 84.90 / Test accuracy (%): 82.60\n",
            "Epoch # 7 / Train accuracy (%): 88.90 / Test accuracy (%): 84.10\n",
            "Epoch # 8 / Train accuracy (%): 93.00 / Test accuracy (%): 83.60\n",
            "Epoch # 9 / Train accuracy (%): 90.80 / Test accuracy (%): 81.20\n",
            "Epoch # 10 / Train accuracy (%): 93.20 / Test accuracy (%): 81.70\n",
            "Epoch # 11 / Train accuracy (%): 94.70 / Test accuracy (%): 83.30\n",
            "Epoch # 12 / Train accuracy (%): 93.40 / Test accuracy (%): 81.80\n",
            "Epoch # 13 / Train accuracy (%): 87.00 / Test accuracy (%): 79.00\n",
            "Epoch # 14 / Train accuracy (%): 97.70 / Test accuracy (%): 84.00\n",
            "Epoch # 15 / Train accuracy (%): 97.60 / Test accuracy (%): 84.30\n",
            "Epoch # 16 / Train accuracy (%): 99.20 / Test accuracy (%): 84.90\n",
            "Epoch # 17 / Train accuracy (%): 99.60 / Test accuracy (%): 84.70\n",
            "Epoch # 18 / Train accuracy (%): 99.60 / Test accuracy (%): 83.70\n",
            "Epoch # 19 / Train accuracy (%): 99.90 / Test accuracy (%): 83.50\n",
            "Epoch # 20 / Train accuracy (%): 99.90 / Test accuracy (%): 83.00\n",
            "Epoch # 21 / Train accuracy (%): 100.00 / Test accuracy (%): 83.10\n",
            "Epoch # 22 / Train accuracy (%): 100.00 / Test accuracy (%): 83.60\n",
            "Epoch # 23 / Train accuracy (%): 100.00 / Test accuracy (%): 83.50\n",
            "Epoch # 24 / Train accuracy (%): 100.00 / Test accuracy (%): 84.20\n",
            "Epoch # 25 / Train accuracy (%): 100.00 / Test accuracy (%): 84.10\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "0p87ybRWLvBV",
        "outputId": "c960e152-5bdf-4d9a-dc4b-14be7161bbd1"
      },
      "source": [
        "# Net with weight sharing\n",
        "model2 = Net2()\n",
        "training_model(model2,train_input,train_target,train_classes,test_input,test_target,test_classes,eta,epochs = 25,batch_size = 50)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch # 1 / Train accuracy (%): 72.70 / Test accuracy (%): 71.20\n",
            "Epoch # 2 / Train accuracy (%): 74.60 / Test accuracy (%): 75.90\n",
            "Epoch # 3 / Train accuracy (%): 84.90 / Test accuracy (%): 81.50\n",
            "Epoch # 4 / Train accuracy (%): 83.30 / Test accuracy (%): 79.50\n",
            "Epoch # 5 / Train accuracy (%): 88.60 / Test accuracy (%): 83.10\n",
            "Epoch # 6 / Train accuracy (%): 90.00 / Test accuracy (%): 83.60\n",
            "Epoch # 7 / Train accuracy (%): 92.90 / Test accuracy (%): 84.80\n",
            "Epoch # 8 / Train accuracy (%): 94.40 / Test accuracy (%): 85.80\n",
            "Epoch # 9 / Train accuracy (%): 95.90 / Test accuracy (%): 85.70\n",
            "Epoch # 10 / Train accuracy (%): 96.10 / Test accuracy (%): 85.40\n",
            "Epoch # 11 / Train accuracy (%): 97.00 / Test accuracy (%): 85.70\n",
            "Epoch # 12 / Train accuracy (%): 98.10 / Test accuracy (%): 85.60\n",
            "Epoch # 13 / Train accuracy (%): 98.10 / Test accuracy (%): 85.80\n",
            "Epoch # 14 / Train accuracy (%): 98.60 / Test accuracy (%): 85.60\n",
            "Epoch # 15 / Train accuracy (%): 98.70 / Test accuracy (%): 85.10\n",
            "Epoch # 16 / Train accuracy (%): 99.10 / Test accuracy (%): 86.50\n",
            "Epoch # 17 / Train accuracy (%): 99.40 / Test accuracy (%): 85.80\n",
            "Epoch # 18 / Train accuracy (%): 99.70 / Test accuracy (%): 86.30\n",
            "Epoch # 19 / Train accuracy (%): 99.80 / Test accuracy (%): 85.90\n",
            "Epoch # 20 / Train accuracy (%): 100.00 / Test accuracy (%): 86.10\n",
            "Epoch # 21 / Train accuracy (%): 100.00 / Test accuracy (%): 86.10\n",
            "Epoch # 22 / Train accuracy (%): 100.00 / Test accuracy (%): 86.10\n",
            "Epoch # 23 / Train accuracy (%): 100.00 / Test accuracy (%): 86.00\n",
            "Epoch # 24 / Train accuracy (%): 100.00 / Test accuracy (%): 86.20\n",
            "Epoch # 25 / Train accuracy (%): 100.00 / Test accuracy (%): 86.20\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' '"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}